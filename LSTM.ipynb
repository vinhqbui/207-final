{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 15:13:18.418828: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:13:18.442271: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 15:13:18.442298: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 15:13:18.442928: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 15:13:18.448140: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 15:13:18.930644: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 15:13:19.814085: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-04 15:13:19.835095: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-04 15:13:19.835138: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-04 15:13:19.838304: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-04 15:13:19.838349: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-04 15:13:19.838363: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-04 15:13:19.934413: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-04 15:13:19.934471: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-04 15:13:19.934476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-04 15:13:19.934498: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-04 15:13:19.934516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4924 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:06:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 15:13:23.571368: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-03-04 15:13:24.270790: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fcbd267fa60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-04 15:13:24.270826: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Ti, Compute Capability 8.6\n",
      "2024-03-04 15:13:24.274204: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1709594004.330083   52763 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 3s 15ms/step - loss: 0.6926 - accuracy: 0.5361 - val_loss: 0.6979 - val_accuracy: 0.4859\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.5311 - val_loss: 0.7000 - val_accuracy: 0.4859\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.6913 - accuracy: 0.5304 - val_loss: 0.6967 - val_accuracy: 0.4802\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.6919 - accuracy: 0.5292 - val_loss: 0.6974 - val_accuracy: 0.4859\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.6923 - accuracy: 0.5342 - val_loss: 0.6950 - val_accuracy: 0.4463\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.6919 - accuracy: 0.5242 - val_loss: 0.6976 - val_accuracy: 0.4915\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.6919 - accuracy: 0.5273 - val_loss: 0.6966 - val_accuracy: 0.4859\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.6914 - accuracy: 0.5342 - val_loss: 0.6979 - val_accuracy: 0.4859\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.6911 - accuracy: 0.5342 - val_loss: 0.6988 - val_accuracy: 0.4859\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.6915 - accuracy: 0.5311 - val_loss: 0.6972 - val_accuracy: 0.4859\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.6903 - accuracy: 0.5367 - val_loss: 0.6970 - val_accuracy: 0.4859\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.6906 - accuracy: 0.5399 - val_loss: 0.6985 - val_accuracy: 0.4859\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.6912 - accuracy: 0.5323 - val_loss: 0.6982 - val_accuracy: 0.4859\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.6909 - accuracy: 0.5342 - val_loss: 0.6976 - val_accuracy: 0.4859\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.6910 - accuracy: 0.5323 - val_loss: 0.6979 - val_accuracy: 0.4859\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5214\n",
      "Test Loss: 0.6931407451629639, Test Accuracy: 0.5214446783065796\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "df = pd.read_csv('apple_processed_data.csv')\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "feature_columns = ['close', 'open', 'lowest', 'highest', 'total_vol', 'mean_vol', 'std_vol']\n",
    "target_column = 'is_up'\n",
    "\n",
    "# Data Preprocessing\n",
    "# Scale features\n",
    "scaler = MinMaxScaler()\n",
    "df[feature_columns] = scaler.fit_transform(df[feature_columns])\n",
    "\n",
    "# Generate sequences\n",
    "def create_sequences(data, feature_columns, target_column, sequence_length):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        sequence = data[feature_columns].iloc[i:i + sequence_length].values\n",
    "        label = data[target_column].iloc[i + sequence_length]\n",
    "        sequences.append(sequence)\n",
    "        labels.append(label)\n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "sequence_length = 10  # Number of days in a sequence\n",
    "X, y = create_sequences(df, feature_columns, target_column, sequence_length)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model Building\n",
    "model = Sequential([\n",
    "    LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(50),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compilation\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_split=0.1, batch_size=32, callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "# Evaluation\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {test_loss}, Test Accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
