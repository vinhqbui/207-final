{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-02 20:28:41.204694: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-02 20:28:41.204784: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-02 20:28:41.204799: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-02 20:28:41.205003: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-02 20:28:41.205017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-02 20:28:41.205045: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:8"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "87] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-02 20:28:41.205063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 5592 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:06:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost\n",
    "from xgboost import  XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.test.is_gpu_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_data = pd.read_csv(\"apple_processed_data.csv\", index_col=0)\n",
    "tesla_data = pd.read_csv(\"tesla_processed_data.csv\", index_col=0)\n",
    "\n",
    "apple_data['month'] = apple_data['month'].astype('category')\n",
    "apple_data['day'] = apple_data['day'].astype('category')\n",
    "\n",
    "tesla_data['month'] = tesla_data['month'].astype('category')\n",
    "tesla_data['day'] = tesla_data['day'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_test(data, target, split):\n",
    "    train, valid, test = split\n",
    "    n = data.shape[0]\n",
    "    train_end = int(train * n)\n",
    "    valid_end = int(n * (train + valid))\n",
    "    x_train, y_train = data[:train_end], target[:train_end]\n",
    "    x_val, y_val = data[train_end:valid_end], target[train_end:valid_end]\n",
    "    x_test, y_test = data[valid_end:], target[valid_end:]\n",
    "\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>lowest</th>\n",
       "      <th>highest</th>\n",
       "      <th>total_vol</th>\n",
       "      <th>mean_vol</th>\n",
       "      <th>std_vol</th>\n",
       "      <th>news</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>is_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>24.490</td>\n",
       "      <td>24.925</td>\n",
       "      <td>24.026</td>\n",
       "      <td>24.992</td>\n",
       "      <td>188181988</td>\n",
       "      <td>482517.917949</td>\n",
       "      <td>453958.983288</td>\n",
       "      <td>[\"Is Xiaomi's first laptop a MacBook Air knock...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>23.807</td>\n",
       "      <td>24.192</td>\n",
       "      <td>23.592</td>\n",
       "      <td>24.366</td>\n",
       "      <td>200586492</td>\n",
       "      <td>514324.338462</td>\n",
       "      <td>426711.446836</td>\n",
       "      <td>[\"Is Xiaomi's first laptop a MacBook Air knock...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>23.802</td>\n",
       "      <td>23.842</td>\n",
       "      <td>23.417</td>\n",
       "      <td>24.092</td>\n",
       "      <td>237766160</td>\n",
       "      <td>609656.820513</td>\n",
       "      <td>452106.984355</td>\n",
       "      <td>[\"Is Xiaomi's first laptop a MacBook Air knock...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>24.143</td>\n",
       "      <td>24.017</td>\n",
       "      <td>23.879</td>\n",
       "      <td>24.265</td>\n",
       "      <td>137809632</td>\n",
       "      <td>353358.030769</td>\n",
       "      <td>315345.332594</td>\n",
       "      <td>Apple aims at bendable devices\\nA newly issued...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>25.066</td>\n",
       "      <td>24.391</td>\n",
       "      <td>24.328</td>\n",
       "      <td>25.151</td>\n",
       "      <td>201020076</td>\n",
       "      <td>515436.092308</td>\n",
       "      <td>344928.788130</td>\n",
       "      <td>Xiaomi's buying spree gives Apple, Samsung mor...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   close    open  lowest  highest  total_vol       mean_vol  \\\n",
       "0  2015-01-02  24.490  24.925  24.026   24.992  188181988  482517.917949   \n",
       "1  2015-01-05  23.807  24.192  23.592   24.366  200586492  514324.338462   \n",
       "2  2015-01-06  23.802  23.842  23.417   24.092  237766160  609656.820513   \n",
       "3  2015-01-07  24.143  24.017  23.879   24.265  137809632  353358.030769   \n",
       "4  2015-01-08  25.066  24.391  24.328   25.151  201020076  515436.092308   \n",
       "\n",
       "         std_vol                                               news month day  \\\n",
       "0  453958.983288  [\"Is Xiaomi's first laptop a MacBook Air knock...     1   2   \n",
       "1  426711.446836  [\"Is Xiaomi's first laptop a MacBook Air knock...     1   5   \n",
       "2  452106.984355  [\"Is Xiaomi's first laptop a MacBook Air knock...     1   6   \n",
       "3  315345.332594  Apple aims at bendable devices\\nA newly issued...     1   7   \n",
       "4  344928.788130  Xiaomi's buying spree gives Apple, Samsung mor...     1   8   \n",
       "\n",
       "   is_up  \n",
       "0      0  \n",
       "1      0  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = apple_data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>lowest</th>\n",
       "      <th>highest</th>\n",
       "      <th>ema5</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>lag_4</th>\n",
       "      <th>lag_5</th>\n",
       "      <th>lag_6</th>\n",
       "      <th>lag_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24.697</td>\n",
       "      <td>24.958</td>\n",
       "      <td>24.375</td>\n",
       "      <td>25.297</td>\n",
       "      <td>24.636187</td>\n",
       "      <td>24.481</td>\n",
       "      <td>25.095</td>\n",
       "      <td>25.066</td>\n",
       "      <td>24.143</td>\n",
       "      <td>23.802</td>\n",
       "      <td>23.807</td>\n",
       "      <td>24.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24.600</td>\n",
       "      <td>24.468</td>\n",
       "      <td>24.283</td>\n",
       "      <td>24.779</td>\n",
       "      <td>24.623803</td>\n",
       "      <td>24.697</td>\n",
       "      <td>24.481</td>\n",
       "      <td>25.095</td>\n",
       "      <td>25.066</td>\n",
       "      <td>24.143</td>\n",
       "      <td>23.802</td>\n",
       "      <td>23.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23.936</td>\n",
       "      <td>24.521</td>\n",
       "      <td>23.871</td>\n",
       "      <td>24.682</td>\n",
       "      <td>24.390489</td>\n",
       "      <td>24.600</td>\n",
       "      <td>24.697</td>\n",
       "      <td>24.481</td>\n",
       "      <td>25.095</td>\n",
       "      <td>25.066</td>\n",
       "      <td>24.143</td>\n",
       "      <td>23.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>23.746</td>\n",
       "      <td>23.990</td>\n",
       "      <td>23.545</td>\n",
       "      <td>24.126</td>\n",
       "      <td>24.173147</td>\n",
       "      <td>23.936</td>\n",
       "      <td>24.600</td>\n",
       "      <td>24.697</td>\n",
       "      <td>24.481</td>\n",
       "      <td>25.095</td>\n",
       "      <td>25.066</td>\n",
       "      <td>24.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>24.358</td>\n",
       "      <td>24.051</td>\n",
       "      <td>23.836</td>\n",
       "      <td>24.395</td>\n",
       "      <td>24.235243</td>\n",
       "      <td>23.746</td>\n",
       "      <td>23.936</td>\n",
       "      <td>24.600</td>\n",
       "      <td>24.697</td>\n",
       "      <td>24.481</td>\n",
       "      <td>25.095</td>\n",
       "      <td>25.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>171.090</td>\n",
       "      <td>171.810</td>\n",
       "      <td>170.650</td>\n",
       "      <td>173.060</td>\n",
       "      <td>173.174476</td>\n",
       "      <td>173.390</td>\n",
       "      <td>172.960</td>\n",
       "      <td>172.840</td>\n",
       "      <td>175.450</td>\n",
       "      <td>175.840</td>\n",
       "      <td>177.140</td>\n",
       "      <td>178.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>166.760</td>\n",
       "      <td>170.325</td>\n",
       "      <td>165.670</td>\n",
       "      <td>171.377</td>\n",
       "      <td>171.036317</td>\n",
       "      <td>171.090</td>\n",
       "      <td>173.390</td>\n",
       "      <td>172.960</td>\n",
       "      <td>172.840</td>\n",
       "      <td>175.450</td>\n",
       "      <td>175.840</td>\n",
       "      <td>177.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>168.285</td>\n",
       "      <td>167.110</td>\n",
       "      <td>166.830</td>\n",
       "      <td>168.960</td>\n",
       "      <td>170.119212</td>\n",
       "      <td>166.760</td>\n",
       "      <td>171.090</td>\n",
       "      <td>173.390</td>\n",
       "      <td>172.960</td>\n",
       "      <td>172.840</td>\n",
       "      <td>175.450</td>\n",
       "      <td>175.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>170.230</td>\n",
       "      <td>169.160</td>\n",
       "      <td>168.870</td>\n",
       "      <td>171.170</td>\n",
       "      <td>170.156141</td>\n",
       "      <td>168.285</td>\n",
       "      <td>166.760</td>\n",
       "      <td>171.090</td>\n",
       "      <td>173.390</td>\n",
       "      <td>172.960</td>\n",
       "      <td>172.840</td>\n",
       "      <td>175.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>170.770</td>\n",
       "      <td>169.250</td>\n",
       "      <td>167.900</td>\n",
       "      <td>170.900</td>\n",
       "      <td>170.360761</td>\n",
       "      <td>170.230</td>\n",
       "      <td>168.285</td>\n",
       "      <td>166.760</td>\n",
       "      <td>171.090</td>\n",
       "      <td>173.390</td>\n",
       "      <td>172.960</td>\n",
       "      <td>172.840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2216 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        close     open   lowest  highest        ema5    lag_1    lag_2  \\\n",
       "7      24.697   24.958   24.375   25.297   24.636187   24.481   25.095   \n",
       "8      24.600   24.468   24.283   24.779   24.623803   24.697   24.481   \n",
       "9      23.936   24.521   23.871   24.682   24.390489   24.600   24.697   \n",
       "10     23.746   23.990   23.545   24.126   24.173147   23.936   24.600   \n",
       "11     24.358   24.051   23.836   24.395   24.235243   23.746   23.936   \n",
       "...       ...      ...      ...      ...         ...      ...      ...   \n",
       "2218  171.090  171.810  170.650  173.060  173.174476  173.390  172.960   \n",
       "2219  166.760  170.325  165.670  171.377  171.036317  171.090  173.390   \n",
       "2220  168.285  167.110  166.830  168.960  170.119212  166.760  171.090   \n",
       "2221  170.230  169.160  168.870  171.170  170.156141  168.285  166.760   \n",
       "2222  170.770  169.250  167.900  170.900  170.360761  170.230  168.285   \n",
       "\n",
       "        lag_3    lag_4    lag_5    lag_6    lag_7  \n",
       "7      25.066   24.143   23.802   23.807   24.490  \n",
       "8      25.095   25.066   24.143   23.802   23.807  \n",
       "9      24.481   25.095   25.066   24.143   23.802  \n",
       "10     24.697   24.481   25.095   25.066   24.143  \n",
       "11     24.600   24.697   24.481   25.095   25.066  \n",
       "...       ...      ...      ...      ...      ...  \n",
       "2218  172.840  175.450  175.840  177.140  178.675  \n",
       "2219  172.960  172.840  175.450  175.840  177.140  \n",
       "2220  173.390  172.960  172.840  175.450  175.840  \n",
       "2221  171.090  173.390  172.960  172.840  175.450  \n",
       "2222  166.760  171.090  173.390  172.960  172.840  \n",
       "\n",
       "[2216 rows x 12 columns]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = data.drop(['is_up', 'Date', 'news', 'day', 'month', 'total_vol', 'mean_vol', 'std_vol'], axis=1)\n",
    "target = data['is_up']\n",
    "\n",
    "predictors['ema5'] = predictors['close'].ewm(span=5).mean()\n",
    "for i in range(1, 8):\n",
    "    predictors['lag_' + str(i)] = predictors['close'].shift(i)\n",
    "predictors = predictors.iloc[7:]\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test = train_valid_test(predictors, target, (0.6, 0.2, 0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(x_train)\n",
    "x_train_scaled = sc.transform(x_train)\n",
    "x_val_scaled = sc.transform(x_val)\n",
    "x_test_scaled = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model\n",
    "According to EDA, the market was up ~ 52% of the days, so the simplest model would be always predict up, which could potentially achieve 52% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5263157894736842"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counting = data['is_up'].value_counts()\n",
    "BASELINE = counting[1] / np.sum(counting)\n",
    "BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5440180586907449"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, [1] * len(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model has accuracy of ~ **54%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default hyperparameters with some Algo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.8284424379232506\n",
      "Validation accuracy: 0.8194130925507901\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state = 12)\n",
    "lr.fit(x_train_scaled, y_train)\n",
    "\n",
    "print(\"Training accuracy:\", lr.score(x_train_scaled, y_train))\n",
    "print(\"Validation accuracy:\", lr.score(x_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 1.0\n",
      "Validation accuracy: 0.5507900677200903\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, random_state = 7)\n",
    "rf.fit(x_train_scaled, y_train)\n",
    "\n",
    "print(\"Training accuracy:\", rf.score(x_train_scaled, y_train))\n",
    "print(\"Validation accuracy:\", rf.score(x_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lag_7', 0.1788118512299655),\n",
       " ('lag_6', 0.1125848090486385),\n",
       " ('lag_5', 0.09106816712921678),\n",
       " ('lag_2', 0.07585625319896798),\n",
       " ('lag_4', 0.07481224317546097),\n",
       " ('lag_3', 0.07402469786313687),\n",
       " ('ema5', 0.07098761181164438),\n",
       " ('lag_1', 0.06875185402126728),\n",
       " ('close', 0.06531133018745403),\n",
       " ('open', 0.06526522230276896),\n",
       " ('highest', 0.06307675468776391),\n",
       " ('lowest', 0.05944920534371484)]"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(zip(predictors.columns, rf.feature_importances_)), key= lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.7057938299473289\n",
      "Validation accuracy: 0.4672686230248307\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(random_state = 12)\n",
    "ada.fit(x_train_scaled, y_train)\n",
    "\n",
    "print(\"Training accuracy:\", ada.score(x_train_scaled, y_train))\n",
    "print(\"Validation accuracy:\", ada.score(x_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.8954100827689992\n",
      "Validation accuracy: 0.5485327313769752\n"
     ]
    }
   ],
   "source": [
    "cat = CatBoostClassifier(silent=True, random_state = 12)\n",
    "cat.fit(x_train_scaled, y_train)\n",
    "\n",
    "print(\"Training accuracy:\", cat.score(x_train_scaled, y_train))\n",
    "print(\"Validation accuracy:\", cat.score(x_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9984951091045899\n",
      "Validation accuracy: 0.47404063205417607\n"
     ]
    }
   ],
   "source": [
    "xg = XGBClassifier()\n",
    "xg.fit(x_train_scaled, y_train)\n",
    "\n",
    "print(\"Training accuracy:\", xg.score(x_train_scaled, y_train))\n",
    "print(\"Validation accuracy:\", xg.score(x_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_lstm = np.reshape(x_train_scaled, (x_train_scaled.shape[0], x_train_scaled.shape[1], 1))\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "unit = 16\n",
    "model.add(LSTM(unit, return_sequences=False, input_shape=(x_train_lstm.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = 'tanh'))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 3.8611 - accuracy: 0.4891\n",
      "Epoch 2/15\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 1.4986 - accuracy: 0.5004\n",
      "Epoch 3/15\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.7310 - accuracy: 0.5184\n",
      "Epoch 4/15\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.7096 - accuracy: 0.5320\n",
      "Epoch 5/15\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.7070 - accuracy: 0.5214\n",
      "Epoch 6/15\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.7166 - accuracy: 0.5117\n",
      "Epoch 7/15\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.7250 - accuracy: 0.5162\n",
      "Epoch 8/15\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.7089 - accuracy: 0.5124\n",
      "Epoch 9/15\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.7115 - accuracy: 0.5192\n",
      "Epoch 10/15\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.7352 - accuracy: 0.5094\n",
      "Epoch 11/15\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.7173 - accuracy: 0.5094\n",
      "Epoch 12/15\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.7036 - accuracy: 0.5132\n",
      "Epoch 13/15\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.7022 - accuracy: 0.5087\n",
      "Epoch 14/15\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.7088 - accuracy: 0.4823\n",
      "Epoch 15/15\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.7015 - accuracy: 0.5147\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train_scaled, y_train, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "Training accuracy: 0.5259593679458239\n",
      "Validation accuracy: 0.5440180586907449\n"
     ]
    }
   ],
   "source": [
    "threshold = 0\n",
    "y_val_pred = (model.predict(x_val_scaled) > threshold).astype(int)\n",
    "print(\"Training accuracy:\", accuracy_score(y_train, (model.predict(x_train_scaled) > threshold).astype(int)))\n",
    "print(\"Validation accuracy:\", accuracy_score(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna import Trial\n",
    "\n",
    "n_trials = 30\n",
    "random_state = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logis Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_optimize(trial: Trial):\n",
    "    solver = trial.suggest_categorical(\"solver\", [\"newton-cholesky\", \"newton-cholesky\", \"lbfgs\"])\n",
    "    penalty = trial.suggest_categorical(\"penalty\", ['l2', None])\n",
    "    lr = LogisticRegression(penalty=penalty, solver=solver, random_state=random_state)\n",
    "    lr.fit(x_train_scaled, y_train)\n",
    "    y_val_pred = lr.predict(x_val_scaled)\n",
    "    return accuracy_score(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-02 20:28:50,336] A new study created in memory with name: no-name-97e90326-07da-4f13-a526-5b36b1e30544\n",
      "[I 2024-03-02 20:28:50,343] Trial 0 finished with value: 0.8194130925507901 and parameters: {'solver': 'newton-cholesky', 'penalty': 'l2'}. Best is trial 0 with value: 0.8194130925507901.\n",
      "[I 2024-03-02 20:28:50,358] Trial 1 finished with value: 0.9909706546275395 and parameters: {'solver': 'lbfgs', 'penalty': None}. Best is trial 1 with value: 0.9909706546275395.\n",
      "[I 2024-03-02 20:28:50,370] Trial 2 finished with value: 0.9909706546275395 and parameters: {'solver': 'lbfgs', 'penalty': None}. Best is trial 1 with value: 0.9909706546275395.\n",
      "/home/vinhbui/miniconda3/envs/neural-net/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #10. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "[I 2024-03-02 20:28:50,377] Trial 3 finished with value: 0.9954853273137697 and parameters: {'solver': 'newton-cholesky', 'penalty': None}. Best is trial 3 with value: 0.9954853273137697.\n",
      "[I 2024-03-02 20:28:50,381] Trial 4 finished with value: 0.8194130925507901 and parameters: {'solver': 'newton-cholesky', 'penalty': 'l2'}. Best is trial 3 with value: 0.9954853273137697.\n",
      "[I 2024-03-02 20:28:50,391] Trial 5 finished with value: 0.8194130925507901 and parameters: {'solver': 'lbfgs', 'penalty': 'l2'}. Best is trial 3 with value: 0.9954853273137697.\n",
      "/home/vinhbui/miniconda3/envs/neural-net/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #10. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "[I 2024-03-02 20:28:50,401] Trial 6 finished with value: 0.9954853273137697 and parameters: {'solver': 'newton-cholesky', 'penalty': None}. Best is trial 3 with value: 0.9954853273137697.\n",
      "[I 2024-03-02 20:28:50,407] Trial 7 finished with value: 0.8194130925507901 and parameters: {'solver': 'newton-cholesky', 'penalty': 'l2'}. Best is trial 3 with value: 0.9954853273137697.\n",
      "/home/vinhbui/miniconda3/envs/neural-net/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #10. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "[I 2024-03-02 20:28:50,419] Trial 8 finished with value: 0.9954853273137697 and parameters: {'solver': 'newton-cholesky', 'penalty': None}. Best is trial 3 with value: 0.9954853273137697.\n",
      "[I 2024-03-02 20:28:50,425] Trial 9 finished with value: 0.8194130925507901 and parameters: {'solver': 'newton-cholesky', 'penalty': 'l2'}. Best is trial 3 with value: 0.9954853273137697.\n",
      "/home/vinhbui/miniconda3/envs/neural-net/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #10. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "[I 2024-03-02 20:28:50,436] Trial 10 finished with value: 0.9954853273137697 and parameters: {'solver': 'newton-cholesky', 'penalty': None}. Best is trial 3 with value: 0.9954853273137697.\n",
      "/home/vinhbui/miniconda3/envs/neural-net/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #10. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "[I 2024-03-02 20:28:50,444] Trial 11 finished with value: 0.9954853273137697 and parameters: {'solver': 'newton-cholesky', 'penalty': None}. Best is trial 3 with value: 0.9954853273137697.\n",
      "/home/vinhbui/miniconda3/envs/neural-net/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #10. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "[I 2024-03-02 20:28:50,451] Trial 12 finished with value: 0.9954853273137697 and parameters: {'solver': 'newton-cholesky', 'penalty': None}. Best is trial 3 with value: 0.9954853273137697.\n",
      "/home/vinhbui/miniconda3/envs/neural-net/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #10. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "[I 2024-03-02 20:28:50,459] Trial 13 finished with value: 0.9954853273137697 and parameters: {'solver': 'newton-cholesky', 'penalty': None}. Best is trial 3 with value: 0.9954853273137697.\n",
      "/home/vinhbui/miniconda3/envs/neural-net/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #10. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "[I 2024-03-02 20:28:50,468] Trial 14 finished with value: 0.9954853273137697 and parameters: {'solver': 'newton-cholesky', 'penalty': None}. Best is trial 3 with value: 0.9954853273137697.\n",
      "/home/vinhbui/miniconda3/envs/neural-net/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #10. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "[I 2024-03-02 20:28:50,478] Trial 15 finished with value: 0.9954853273137697 and parameters: {'solver': 'newton-cholesky', 'penalty': None}. Best is trial 3 with value: 0.9954853273137697.\n",
      "/home/vinhbui/miniconda3/envs/neural-net/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #10. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "[I 2024-03-02 20:28:50,486] Trial 16 finished with value: 0.9954853273137697 and parameters: {'solver': 'newton-cholesky', 'penalty': None}. Best is trial 3 with value: 0.9954853273137697.\n",
      "/home/vinhbui/miniconda3/envs/neural-net/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #10. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "[I 2024-03-02 20:28:50,512] Trial 17 finished with value: 0.9954853273137697 and parameters: {'solver': 'newton-cholesky', 'penalty': None}. Best is trial 3 with value: 0.9954853273137697.\n",
      "/home/vinhbui/miniconda3/envs/neural-net/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #10. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "[I 2024-03-02 20:28:50,521] Trial 18 finished with value: 0.9954853273137697 and parameters: {'solver': 'newton-cholesky', 'penalty': None}. Best is trial 3 with value: 0.9954853273137697.\n",
      "/home/vinhbui/miniconda3/envs/neural-net/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #10. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "[I 2024-03-02 20:28:50,528] Trial 19 finished with value: 0.9954853273137697 and parameters: {'solver': 'newton-cholesky', 'penalty': None}. Best is trial 3 with value: 0.9954853273137697.\n",
      "/home/vinhbui/miniconda3/envs/neural-net/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #10. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "[I 2024-03-02 20:28:50,540] Trial 20 finished with value: 0.9954853273137697 and parameters: {'solver': 'newton-cholesky', 'penalty': None}. Best is trial 3 with value: 0.9954853273137697.\n",
      "/home/vinhbui/miniconda3/envs/neural-net/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #10. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "[I 2024-03-02 20:28:50,549] Trial 21 finished with value: 0.9954853273137697 and parameters: {'solver': 'newton-cholesky', 'penalty': None}. Best is trial 3 with value: 0.9954853273137697.\n",
      "/home/vinhbui/miniconda3/envs/neural-net/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #10. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "[I 2024-03-02 20:28:50,557] Trial 22 finished with value: 0.9954853273137697 and parameters: {'solver': 'newton-cholesky', 'penalty': None}. Best is trial 3 with value: 0.9954853273137697.\n",
      "/home/vinhbui/miniconda3/envs/neural-net/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #10. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "[I 2024-03-02 20:28:50,562] Trial 23 finished with value: 0.9954853273137697 and parameters: {'solver': 'newton-cholesky', 'penalty': None}. Best is trial 3 with value: 0.9954853273137697.\n",
      "/home/vinhbui/miniconda3/envs/neural-net/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #10. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "[I 2024-03-02 20:28:50,570] Trial 24 finished with value: 0.9954853273137697 and parameters: {'solver': 'newton-cholesky', 'penalty': None}. Best is trial 3 with value: 0.9954853273137697.\n",
      "/home/vinhbui/miniconda3/envs/neural-net/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #10. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "[I 2024-03-02 20:28:50,578] Trial 25 finished with value: 0.9954853273137697 and parameters: {'solver': 'newton-cholesky', 'penalty': None}. Best is trial 3 with value: 0.9954853273137697.\n",
      "[I 2024-03-02 20:28:50,583] Trial 26 finished with value: 0.8194130925507901 and parameters: {'solver': 'newton-cholesky', 'penalty': 'l2'}. Best is trial 3 with value: 0.9954853273137697.\n",
      "/home/vinhbui/miniconda3/envs/neural-net/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #10. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "[I 2024-03-02 20:28:50,591] Trial 27 finished with value: 0.9954853273137697 and parameters: {'solver': 'newton-cholesky', 'penalty': None}. Best is trial 3 with value: 0.9954853273137697.\n",
      "/home/vinhbui/miniconda3/envs/neural-net/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #10. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "[I 2024-03-02 20:28:50,596] Trial 28 finished with value: 0.9954853273137697 and parameters: {'solver': 'newton-cholesky', 'penalty': None}. Best is trial 3 with value: 0.9954853273137697.\n",
      "[I 2024-03-02 20:28:50,601] Trial 29 finished with value: 0.8194130925507901 and parameters: {'solver': 'newton-cholesky', 'penalty': 'l2'}. Best is trial 3 with value: 0.9954853273137697.\n"
     ]
    }
   ],
   "source": [
    "lr_study = optuna.create_study(direction=\"maximize\")\n",
    "lr_study.optimize(lr_optimize, n_trials=n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params {'solver': 'newton-cholesky', 'penalty': None}\n",
      "Best accuracy 0.9954853273137697\n"
     ]
    }
   ],
   "source": [
    "print(\"Best params\", lr_study.best_params)\n",
    "print(\"Best accuracy\", lr_study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1772, 12)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack([x_train_scaled, x_val_scaled]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_optimize(trial: Trial):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
