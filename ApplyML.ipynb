{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-08 00:31:24.931140: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-08 00:31:24.931245: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-08 00:31:24.931264: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-08 00:31:24.931420: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-08 00:31:24.931428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-08 00:31:24.931447: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-08 00:31:24.931463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 5592 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:06:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost\n",
    "from xgboost import  XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.test.is_gpu_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_data = pd.read_csv(\"apple_processed_data.csv\", index_col=0)\n",
    "tesla_data = pd.read_csv(\"tesla_processed_data.csv\", index_col=0)\n",
    "\n",
    "apple_data['month'] = apple_data['month'].astype('category')\n",
    "apple_data['day'] = apple_data['day'].astype('category')\n",
    "\n",
    "tesla_data['month'] = tesla_data['month'].astype('category')\n",
    "tesla_data['day'] = tesla_data['day'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>lowest</th>\n",
       "      <th>highest</th>\n",
       "      <th>total_vol</th>\n",
       "      <th>mean_vol</th>\n",
       "      <th>std_vol</th>\n",
       "      <th>news</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>is_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>14.613</td>\n",
       "      <td>14.865</td>\n",
       "      <td>14.217</td>\n",
       "      <td>14.883</td>\n",
       "      <td>59157390</td>\n",
       "      <td>151685.615385</td>\n",
       "      <td>155760.920466</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>14.001</td>\n",
       "      <td>14.351</td>\n",
       "      <td>13.811</td>\n",
       "      <td>14.433</td>\n",
       "      <td>68662800</td>\n",
       "      <td>176058.461538</td>\n",
       "      <td>168290.638752</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>14.079</td>\n",
       "      <td>14.003</td>\n",
       "      <td>13.614</td>\n",
       "      <td>14.280</td>\n",
       "      <td>80752635</td>\n",
       "      <td>207058.038462</td>\n",
       "      <td>152662.243747</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>14.054</td>\n",
       "      <td>14.219</td>\n",
       "      <td>13.985</td>\n",
       "      <td>14.319</td>\n",
       "      <td>38728110</td>\n",
       "      <td>99558.123393</td>\n",
       "      <td>100907.065350</td>\n",
       "      <td>['BMW revives wireless charging to reduce elec...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>14.037</td>\n",
       "      <td>14.216</td>\n",
       "      <td>14.001</td>\n",
       "      <td>14.253</td>\n",
       "      <td>43839960</td>\n",
       "      <td>112699.125964</td>\n",
       "      <td>130930.670726</td>\n",
       "      <td>['How oil at $50 could change almost everythin...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   close    open  lowest  highest  total_vol       mean_vol  \\\n",
       "0  2015-01-02  14.613  14.865  14.217   14.883   59157390  151685.615385   \n",
       "1  2015-01-05  14.001  14.351  13.811   14.433   68662800  176058.461538   \n",
       "2  2015-01-06  14.079  14.003  13.614   14.280   80752635  207058.038462   \n",
       "3  2015-01-07  14.054  14.219  13.985   14.319   38728110   99558.123393   \n",
       "4  2015-01-08  14.037  14.216  14.001   14.253   43839960  112699.125964   \n",
       "\n",
       "         std_vol                                               news month day  \\\n",
       "0  155760.920466                                                        1   2   \n",
       "1  168290.638752                                                        1   5   \n",
       "2  152662.243747                                                        1   6   \n",
       "3  100907.065350  ['BMW revives wireless charging to reduce elec...     1   7   \n",
       "4  130930.670726  ['How oil at $50 could change almost everythin...     1   8   \n",
       "\n",
       "   is_up  \n",
       "0      0  \n",
       "1      1  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesla_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_test(data, target, split):\n",
    "    train, valid, test = split\n",
    "    n = data.shape[0]\n",
    "    train_end = int(train * n)\n",
    "    valid_end = int(n * (train + valid))\n",
    "    print(valid_end)\n",
    "    x_train, y_train = data[:train_end], target[:train_end]\n",
    "    x_val, y_val = data[train_end:valid_end], target[train_end:valid_end]\n",
    "    x_test, y_test = data[valid_end:], target[valid_end:]\n",
    "\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = apple_data\n",
    "lag = 10\n",
    "data['ema'] = data['close'].ewm(span=lag).mean()\n",
    "for i in range(1, lag+1):\n",
    "    data['lag_' + str(i)] = data['close'].shift(i)\n",
    "\n",
    "data = data.iloc[lag:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>lowest</th>\n",
       "      <th>highest</th>\n",
       "      <th>total_vol</th>\n",
       "      <th>mean_vol</th>\n",
       "      <th>std_vol</th>\n",
       "      <th>news</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_11</th>\n",
       "      <th>lag_12</th>\n",
       "      <th>lag_13</th>\n",
       "      <th>lag_14</th>\n",
       "      <th>lag_15</th>\n",
       "      <th>lag_16</th>\n",
       "      <th>lag_17</th>\n",
       "      <th>lag_18</th>\n",
       "      <th>lag_19</th>\n",
       "      <th>lag_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2015-02-02</td>\n",
       "      <td>26.578</td>\n",
       "      <td>26.454</td>\n",
       "      <td>25.980</td>\n",
       "      <td>26.724</td>\n",
       "      <td>220454064</td>\n",
       "      <td>565266.830769</td>\n",
       "      <td>413035.047275</td>\n",
       "      <td>[\"Apple's spectacular Q3 performance from an I...</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>23.936</td>\n",
       "      <td>24.600</td>\n",
       "      <td>24.697</td>\n",
       "      <td>24.481</td>\n",
       "      <td>25.095</td>\n",
       "      <td>25.066</td>\n",
       "      <td>24.143</td>\n",
       "      <td>23.802</td>\n",
       "      <td>23.807</td>\n",
       "      <td>24.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2015-02-03</td>\n",
       "      <td>26.573</td>\n",
       "      <td>26.575</td>\n",
       "      <td>26.322</td>\n",
       "      <td>26.706</td>\n",
       "      <td>174221580</td>\n",
       "      <td>446722.000000</td>\n",
       "      <td>328806.289399</td>\n",
       "      <td>[\"Apple's spectacular Q3 performance from an I...</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>23.746</td>\n",
       "      <td>23.936</td>\n",
       "      <td>24.600</td>\n",
       "      <td>24.697</td>\n",
       "      <td>24.481</td>\n",
       "      <td>25.095</td>\n",
       "      <td>25.066</td>\n",
       "      <td>24.143</td>\n",
       "      <td>23.802</td>\n",
       "      <td>23.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2015-02-04</td>\n",
       "      <td>26.786</td>\n",
       "      <td>26.533</td>\n",
       "      <td>26.479</td>\n",
       "      <td>27.025</td>\n",
       "      <td>252725380</td>\n",
       "      <td>648013.794872</td>\n",
       "      <td>712862.564754</td>\n",
       "      <td>Steve Jobs's biopic will hit the screens in Oc...</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>24.358</td>\n",
       "      <td>23.746</td>\n",
       "      <td>23.936</td>\n",
       "      <td>24.600</td>\n",
       "      <td>24.697</td>\n",
       "      <td>24.481</td>\n",
       "      <td>25.095</td>\n",
       "      <td>25.066</td>\n",
       "      <td>24.143</td>\n",
       "      <td>23.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2015-02-05</td>\n",
       "      <td>26.979</td>\n",
       "      <td>26.938</td>\n",
       "      <td>26.794</td>\n",
       "      <td>27.068</td>\n",
       "      <td>144629728</td>\n",
       "      <td>370845.456410</td>\n",
       "      <td>376791.267099</td>\n",
       "      <td>Cashless ecosystem: National Payment Corporati...</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>24.546</td>\n",
       "      <td>24.358</td>\n",
       "      <td>23.746</td>\n",
       "      <td>23.936</td>\n",
       "      <td>24.600</td>\n",
       "      <td>24.697</td>\n",
       "      <td>24.481</td>\n",
       "      <td>25.095</td>\n",
       "      <td>25.066</td>\n",
       "      <td>24.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2015-02-06</td>\n",
       "      <td>26.748</td>\n",
       "      <td>27.020</td>\n",
       "      <td>26.615</td>\n",
       "      <td>27.073</td>\n",
       "      <td>155597272</td>\n",
       "      <td>398967.364103</td>\n",
       "      <td>297534.236592</td>\n",
       "      <td>Global leaders to explore 'technology 20 years...</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>25.182</td>\n",
       "      <td>24.546</td>\n",
       "      <td>24.358</td>\n",
       "      <td>23.746</td>\n",
       "      <td>23.936</td>\n",
       "      <td>24.600</td>\n",
       "      <td>24.697</td>\n",
       "      <td>24.481</td>\n",
       "      <td>25.095</td>\n",
       "      <td>25.066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date   close    open  lowest  highest  total_vol       mean_vol  \\\n",
       "20  2015-02-02  26.578  26.454  25.980   26.724  220454064  565266.830769   \n",
       "21  2015-02-03  26.573  26.575  26.322   26.706  174221580  446722.000000   \n",
       "22  2015-02-04  26.786  26.533  26.479   27.025  252725380  648013.794872   \n",
       "23  2015-02-05  26.979  26.938  26.794   27.068  144629728  370845.456410   \n",
       "24  2015-02-06  26.748  27.020  26.615   27.073  155597272  398967.364103   \n",
       "\n",
       "          std_vol                                               news month  \\\n",
       "20  413035.047275  [\"Apple's spectacular Q3 performance from an I...     2   \n",
       "21  328806.289399  [\"Apple's spectacular Q3 performance from an I...     2   \n",
       "22  712862.564754  Steve Jobs's biopic will hit the screens in Oc...     2   \n",
       "23  376791.267099  Cashless ecosystem: National Payment Corporati...     2   \n",
       "24  297534.236592  Global leaders to explore 'technology 20 years...     2   \n",
       "\n",
       "    ...  lag_11  lag_12  lag_13  lag_14  lag_15  lag_16  lag_17  lag_18  \\\n",
       "20  ...  23.936  24.600  24.697  24.481  25.095  25.066  24.143  23.802   \n",
       "21  ...  23.746  23.936  24.600  24.697  24.481  25.095  25.066  24.143   \n",
       "22  ...  24.358  23.746  23.936  24.600  24.697  24.481  25.095  25.066   \n",
       "23  ...  24.546  24.358  23.746  23.936  24.600  24.697  24.481  25.095   \n",
       "24  ...  25.182  24.546  24.358  23.746  23.936  24.600  24.697  24.481   \n",
       "\n",
       "    lag_19  lag_20  \n",
       "20  23.807  24.490  \n",
       "21  23.802  23.807  \n",
       "22  24.143  23.802  \n",
       "23  25.066  24.143  \n",
       "24  25.095  25.066  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = data.drop(['is_up', 'Date', 'news', 'day', 'month', 'total_vol', 'mean_vol', 'std_vol', 'open'], axis=1)\n",
    "target = data['is_up']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1762\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test = train_valid_test(predictors, target, (0.6, 0.2, 0.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>lowest</th>\n",
       "      <th>highest</th>\n",
       "      <th>ema</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>lag_4</th>\n",
       "      <th>lag_5</th>\n",
       "      <th>lag_6</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_11</th>\n",
       "      <th>lag_12</th>\n",
       "      <th>lag_13</th>\n",
       "      <th>lag_14</th>\n",
       "      <th>lag_15</th>\n",
       "      <th>lag_16</th>\n",
       "      <th>lag_17</th>\n",
       "      <th>lag_18</th>\n",
       "      <th>lag_19</th>\n",
       "      <th>lag_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>26.578</td>\n",
       "      <td>25.980</td>\n",
       "      <td>26.724</td>\n",
       "      <td>25.283226</td>\n",
       "      <td>26.251</td>\n",
       "      <td>26.650</td>\n",
       "      <td>25.839</td>\n",
       "      <td>24.456</td>\n",
       "      <td>25.339</td>\n",
       "      <td>25.317</td>\n",
       "      <td>...</td>\n",
       "      <td>23.936</td>\n",
       "      <td>24.600</td>\n",
       "      <td>24.697</td>\n",
       "      <td>24.481</td>\n",
       "      <td>25.095</td>\n",
       "      <td>25.066</td>\n",
       "      <td>24.143</td>\n",
       "      <td>23.802</td>\n",
       "      <td>23.807</td>\n",
       "      <td>24.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>26.573</td>\n",
       "      <td>26.322</td>\n",
       "      <td>26.706</td>\n",
       "      <td>25.421337</td>\n",
       "      <td>26.578</td>\n",
       "      <td>26.251</td>\n",
       "      <td>26.650</td>\n",
       "      <td>25.839</td>\n",
       "      <td>24.456</td>\n",
       "      <td>25.339</td>\n",
       "      <td>...</td>\n",
       "      <td>23.746</td>\n",
       "      <td>23.936</td>\n",
       "      <td>24.600</td>\n",
       "      <td>24.697</td>\n",
       "      <td>24.481</td>\n",
       "      <td>25.095</td>\n",
       "      <td>25.066</td>\n",
       "      <td>24.143</td>\n",
       "      <td>23.802</td>\n",
       "      <td>23.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>26.786</td>\n",
       "      <td>26.479</td>\n",
       "      <td>27.025</td>\n",
       "      <td>25.565756</td>\n",
       "      <td>26.573</td>\n",
       "      <td>26.578</td>\n",
       "      <td>26.251</td>\n",
       "      <td>26.650</td>\n",
       "      <td>25.839</td>\n",
       "      <td>24.456</td>\n",
       "      <td>...</td>\n",
       "      <td>24.358</td>\n",
       "      <td>23.746</td>\n",
       "      <td>23.936</td>\n",
       "      <td>24.600</td>\n",
       "      <td>24.697</td>\n",
       "      <td>24.481</td>\n",
       "      <td>25.095</td>\n",
       "      <td>25.066</td>\n",
       "      <td>24.143</td>\n",
       "      <td>23.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>26.979</td>\n",
       "      <td>26.794</td>\n",
       "      <td>27.068</td>\n",
       "      <td>25.713750</td>\n",
       "      <td>26.786</td>\n",
       "      <td>26.573</td>\n",
       "      <td>26.578</td>\n",
       "      <td>26.251</td>\n",
       "      <td>26.650</td>\n",
       "      <td>25.839</td>\n",
       "      <td>...</td>\n",
       "      <td>24.546</td>\n",
       "      <td>24.358</td>\n",
       "      <td>23.746</td>\n",
       "      <td>23.936</td>\n",
       "      <td>24.600</td>\n",
       "      <td>24.697</td>\n",
       "      <td>24.481</td>\n",
       "      <td>25.095</td>\n",
       "      <td>25.066</td>\n",
       "      <td>24.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>26.748</td>\n",
       "      <td>26.615</td>\n",
       "      <td>27.073</td>\n",
       "      <td>25.821038</td>\n",
       "      <td>26.979</td>\n",
       "      <td>26.786</td>\n",
       "      <td>26.573</td>\n",
       "      <td>26.578</td>\n",
       "      <td>26.251</td>\n",
       "      <td>26.650</td>\n",
       "      <td>...</td>\n",
       "      <td>25.182</td>\n",
       "      <td>24.546</td>\n",
       "      <td>24.358</td>\n",
       "      <td>23.746</td>\n",
       "      <td>23.936</td>\n",
       "      <td>24.600</td>\n",
       "      <td>24.697</td>\n",
       "      <td>24.481</td>\n",
       "      <td>25.095</td>\n",
       "      <td>25.066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     close  lowest  highest        ema   lag_1   lag_2   lag_3   lag_4  \\\n",
       "20  26.578  25.980   26.724  25.283226  26.251  26.650  25.839  24.456   \n",
       "21  26.573  26.322   26.706  25.421337  26.578  26.251  26.650  25.839   \n",
       "22  26.786  26.479   27.025  25.565756  26.573  26.578  26.251  26.650   \n",
       "23  26.979  26.794   27.068  25.713750  26.786  26.573  26.578  26.251   \n",
       "24  26.748  26.615   27.073  25.821038  26.979  26.786  26.573  26.578   \n",
       "\n",
       "     lag_5   lag_6  ...  lag_11  lag_12  lag_13  lag_14  lag_15  lag_16  \\\n",
       "20  25.339  25.317  ...  23.936  24.600  24.697  24.481  25.095  25.066   \n",
       "21  24.456  25.339  ...  23.746  23.936  24.600  24.697  24.481  25.095   \n",
       "22  25.839  24.456  ...  24.358  23.746  23.936  24.600  24.697  24.481   \n",
       "23  26.650  25.839  ...  24.546  24.358  23.746  23.936  24.600  24.697   \n",
       "24  26.251  26.650  ...  25.182  24.546  24.358  23.746  23.936  24.600   \n",
       "\n",
       "    lag_17  lag_18  lag_19  lag_20  \n",
       "20  24.143  23.802  23.807  24.490  \n",
       "21  25.066  24.143  23.802  23.807  \n",
       "22  25.095  25.066  24.143  23.802  \n",
       "23  24.481  25.095  25.066  24.143  \n",
       "24  24.697  24.481  25.095  25.066  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = MinMaxScaler()\n",
    "sc.fit(x_train)\n",
    "x_train_scaled = sc.transform(x_train)\n",
    "x_val_scaled = sc.transform(x_val)\n",
    "x_test_scaled = sc.transform(x_test)\n",
    "\n",
    "\n",
    "X_train_for_compare = np.append(x_train_scaled, x_val_scaled, axis=0)\n",
    "Y_train_for_compare = np.append(y_train, y_val, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model\n",
    "According to EDA, the market was up ~ 52% of the days, so the simplest model would be always predict up, which could potentially achieve 52% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5256468452110759"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counting = data['is_up'].value_counts()\n",
    "BASELINE = counting[1] / np.sum(counting)\n",
    "BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5374149659863946"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, [1] * len(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model has accuracy of ~ **54%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default hyperparameters with some Algo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.5397426192278577\n",
      "Validation accuracy: 0.5510204081632653\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state = 12)\n",
    "lr.fit(x_train_scaled, y_train)\n",
    "\n",
    "print(\"Training accuracy:\", lr.score(x_train_scaled, y_train))\n",
    "print(\"Validation accuracy:\", lr.score(x_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Nearest Neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.6805450416351249\n",
      "Validation accuracy: 0.46938775510204084\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train_scaled, y_train)\n",
    "\n",
    "print(\"Training accuracy:\", knn.score(x_train_scaled, y_train))\n",
    "print(\"Validation accuracy:\", knn.score(x_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.5299015897047691\n",
      "Validation accuracy: 0.4943310657596372\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(x_train_scaled, y_train)\n",
    "print(\"Training accuracy:\", svm.score(x_train_scaled, y_train))\n",
    "print(\"Validation accuracy:\", svm.score(x_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.5314155942467828\n",
      "Validation accuracy: 0.5374149659863946\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "bnb.fit(x_train_scaled, y_train)\n",
    "print(\"Training accuracy:\", bnb.score(x_train_scaled, y_train))\n",
    "print(\"Validation accuracy:\", bnb.score(x_val_scaled, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 1.0\n",
      "Validation accuracy: 0.47165532879818595\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, random_state = 7)\n",
    "rf.fit(x_train_scaled, y_train)\n",
    "\n",
    "print(\"Training accuracy:\", rf.score(x_train_scaled, y_train))\n",
    "print(\"Validation accuracy:\", rf.score(x_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lag_7', 0.045138676515350994),\n",
       " ('close', 0.04431636153993201),\n",
       " ('lag_20', 0.04418274716926696),\n",
       " ('lag_8', 0.04415302306653415),\n",
       " ('lag_19', 0.04401352202367309),\n",
       " ('lag_13', 0.04365725178997353),\n",
       " ('lag_16', 0.04336823038092861),\n",
       " ('lag_5', 0.04318335663764783),\n",
       " ('lowest', 0.04272730951636593),\n",
       " ('lag_4', 0.042443121748897764),\n",
       " ('lag_12', 0.04214385369069147),\n",
       " ('lag_9', 0.04204109360042356),\n",
       " ('highest', 0.04192365352242163),\n",
       " ('lag_17', 0.04188088727612056),\n",
       " ('lag_14', 0.041612483145159224),\n",
       " ('lag_6', 0.04094444564718164),\n",
       " ('lag_18', 0.04063767872556414),\n",
       " ('lag_15', 0.04055890586332204),\n",
       " ('lag_10', 0.04010821366419804),\n",
       " ('lag_1', 0.04010268308749807),\n",
       " ('lag_11', 0.039933679791110795),\n",
       " ('lag_2', 0.03834359347079784),\n",
       " ('lag_3', 0.03744867033671835),\n",
       " ('ema', 0.03513655779022182)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(zip(predictors.columns, rf.feature_importances_)), key= lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.8569265707797123\n",
      "Validation accuracy: 0.47165532879818595\n",
      "Test accuracy: 0.48299319727891155\n"
     ]
    }
   ],
   "source": [
    "cat = CatBoostClassifier(silent=True, random_state = 12)\n",
    "cat.fit(x_train_scaled, y_train)\n",
    "\n",
    "print(\"Training accuracy:\", cat.score(x_train_scaled, y_train))\n",
    "print(\"Validation accuracy:\", cat.score(x_val_scaled, y_val))\n",
    "print(\"Test accuracy:\", cat.score(x_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 1.0\n",
      "Validation accuracy: 0.47619047619047616\n",
      "Test accuracy: 0.48299319727891155\n"
     ]
    }
   ],
   "source": [
    "xg = XGBClassifier()\n",
    "xg.fit(x_train_scaled, y_train)\n",
    "\n",
    "print(\"Training accuracy:\", xg.score(x_train_scaled, y_train))\n",
    "print(\"Validation accuracy:\", xg.score(x_val_scaled, y_val))\n",
    "print(\"Test accuracy:\", xg.score(x_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1762/1762 [==============================] - 14s 7ms/step - loss: 0.7915 - accuracy: 0.5000 - val_loss: 0.6934 - val_accuracy: 0.5374\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "Training accuracy: 0.5246025738077215\n",
      "Validation accuracy: 0.5374149659863946\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6963 - accuracy: 0.5170\n",
      "Test accuracy: [0.6962910294532776, 0.5170068144798279]\n"
     ]
    }
   ],
   "source": [
    "x_train_lstm = np.reshape(X_train_for_compare, (X_train_for_compare.shape[0], X_train_for_compare.shape[1], 1))\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "unit = 50\n",
    "model.add(LSTM(unit, return_sequences=True, input_shape=(x_train_lstm.shape[1], 1)))\n",
    "model.add(LSTM(unit))\n",
    "model.add(Dense(units=25))\n",
    "model.add(Dense(1, activation = 'tanh'))\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Nadam()\n",
    "optimizer = tf.keras.optimizers.Adagrad()\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "hist = model.fit(x_train_lstm, Y_train_for_compare, validation_data = (x_val_scaled, y_val), batch_size=1, epochs=1)\n",
    "\n",
    "threshold = 0\n",
    "y_val_pred = (model.predict(x_val_scaled) >= threshold).astype(int)\n",
    "print(\"Training accuracy:\", accuracy_score(y_train, (model.predict(x_train_scaled) > threshold).astype(int)))\n",
    "print(\"Validation accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Test accuracy:\", model.evaluate(x_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna import Trial\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "n_trials = 100\n",
    "random_state = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logis Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_optimize(trial: Trial):\n",
    "    solver = trial.suggest_categorical(\"solver\", [\"newton-cholesky\", \"newton-cholesky\", \"lbfgs\"])\n",
    "    penalty = trial.suggest_categorical(\"penalty\", ['l2', None])\n",
    "    lr = LogisticRegression(penalty=penalty, solver=solver, random_state=random_state, max_iter=500, multi_class = 'ovr')\n",
    "    lr.fit(x_train_scaled, y_train)\n",
    "    y_val_pred = lr.predict(x_val_scaled)\n",
    "    return accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "lr_study = optuna.create_study(direction=\"maximize\")\n",
    "lr_study.optimize(lr_optimize, n_trials=n_trials)\n",
    "\n",
    "lr_study = optuna.create_study(direction=\"maximize\")\n",
    "lr_study.optimize(lr_optimize, n_trials=n_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params {'n_estimators': 90, 'criterion': 'entropy', 'bootstrap': True}\n",
      "Best accuracy 0.5510204081632653\n"
     ]
    }
   ],
   "source": [
    "def rf_optimize(trial: Trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', low=10, high = 100)\n",
    "    criterion = trial.suggest_categorical(\"criterion\", ['gini', 'entropy', 'log_loss'])\n",
    "    bootstrap = trial.suggest_categorical(\"bootstrap\", [True, False])\n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, bootstrap=bootstrap)\n",
    "    lr.fit(x_train_scaled, y_train)\n",
    "    y_val_pred = lr.predict(x_val_scaled)\n",
    "    return accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "rf_study = optuna.create_study(direction=\"maximize\")\n",
    "rf_study.optimize(rf_optimize, n_trials=n_trials)\n",
    "print(\"Best params\", rf_study.best_params)\n",
    "print(\"Best accuracy\", rf_study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params {'iterations': 135, 'depth': 5, 'learning_rate': 0.056908794946172625, 'random_strength': 6, 'bagging_temperature': 0.11268454956917995, 'l2_leaf_reg': 6.353060743995894, 'border_count': 224}\n",
      "Best accuracy 0.5374149659863946\n"
     ]
    }
   ],
   "source": [
    "def catboost_optimize(trial: Trial):\n",
    "    param = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'random_strength': trial.suggest_int('random_strength', 1, 20),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-2, 10.0),\n",
    "        'border_count': trial.suggest_int('border_count', 1, 255),\n",
    "        'loss_function': 'Logloss',\n",
    "        'verbose': False\n",
    "    }\n",
    "    model = CatBoostClassifier(**param)\n",
    "    model.fit(x_train_scaled, y_train, eval_set=[(x_val_scaled, y_val)], early_stopping_rounds=100, verbose=0)\n",
    "    preds = model.predict(x_val_scaled)\n",
    "    accuracy = accuracy_score(y_val, preds)\n",
    "    return accuracy\n",
    "\n",
    "cat_study = optuna.create_study(direction=\"maximize\")\n",
    "cat_study.optimize(catboost_optimize, n_trials=n_trials)\n",
    "print(\"Best params\", cat_study.best_params)\n",
    "print(\"Best accuracy\", cat_study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neural_network_model():\n",
    "    nn = tf.keras.Sequential()\n",
    "    nn.add(Dense(len(x_train_scaled[0])))\n",
    "    nn.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    return nn\n",
    "\n",
    "def create_lstm(units):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(LSTM(units, return_sequences=True, input_shape=(x_train_lstm.shape[1], 1)))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=units))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    return model\n",
    "    \n",
    "def create_neural_network_study(trial: Trial):\n",
    "    model = create_neural_network_model()\n",
    "    optimizer = trial.suggest_categorical('optimizer', \n",
    "                                         [\"Adam\", \"SGD\", \"RMSprop\", \"Adagrad\"])\n",
    "    batch_size = trial.suggest_int('batch_size', low=1, high = 15)\n",
    "    epochs = trial.suggest_int('epochs', low=1, high=5)\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
    "    model.compile(optimizer=getattr(tf.keras.optimizers, optimizer)(learning_rate=lr), loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "    model.fit(x_train_lstm, Y_train_for_compare, validation_data = (x_val_scaled, y_val), batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "    threshold = 0.5\n",
    "    y_val_pred = (model.predict(x_val_scaled) >= threshold).astype(int)\n",
    "    return accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "def create_lstm_study(trial: Trial):\n",
    "    units = trial.suggest_int(\"units\", low=10, high = 50)\n",
    "    model = create_lstm(units)\n",
    "    optimizer = trial.suggest_categorical('optimizer', \n",
    "                                         [\"Adam\", \"SGD\", \"RMSprop\", \"Adagrad\"])\n",
    "    batch_size = trial.suggest_int('batch_size', low=1, high = 15)\n",
    "    epochs = trial.suggest_int('epochs', low=1, high=5)\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
    "    model.compile(optimizer=getattr(tf.keras.optimizers, optimizer)(learning_rate=lr), loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "    model.fit(x_train_lstm, Y_train_for_compare, validation_data = (x_val_scaled, y_val), batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "    threshold = 0.5\n",
    "    y_val_pred = (model.predict(x_val_scaled) >= threshold).astype(int)\n",
    "    return accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "def run_study(function):\n",
    "    # Create an Optuna study and optimize the objective\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(function, n_trials=10)\n",
    "    \n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    \n",
    "    print(f\"Accuracy: {trial.value}\")\n",
    "    print(\"Best hyperparameters:\")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "Best trial:\n",
      "Accuracy: 0.5578231292517006\n",
      "Best hyperparameters:\n",
      "units: 12\n",
      "optimizer: Adam\n",
      "batch_size: 13\n",
      "epochs: 3\n",
      "lr: 0.001526401264743937\n"
     ]
    }
   ],
   "source": [
    "run_study(create_lstm_study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "Best trial:\n",
      "Accuracy: 0.5374149659863946\n",
      "Best hyperparameters:\n",
      "units: 39\n",
      "optimizer: Adagrad\n",
      "batch_size: 4\n",
      "epochs: 2\n",
      "lr: 0.00035360636710591654\n"
     ]
    }
   ],
   "source": [
    "def create_lstm_2(units):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(LSTM(units, return_sequences=True, input_shape=(x_train_lstm.shape[1], 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=units // 2))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    return model\n",
    "\n",
    "def create_lstm_study_2(trial: Trial):\n",
    "    units = trial.suggest_int(\"units\", low=10, high = 50)\n",
    "    model = create_lstm_2(units)\n",
    "    optimizer = trial.suggest_categorical('optimizer', \n",
    "                                         [\"Adam\", \"SGD\", \"RMSprop\", \"Adagrad\"])\n",
    "    batch_size = trial.suggest_int('batch_size', low=1, high = 15)\n",
    "    epochs = trial.suggest_int('epochs', low=1, high=5)\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
    "    model.compile(optimizer=getattr(tf.keras.optimizers, optimizer)(learning_rate=lr), loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "    model.fit(x_train_lstm, Y_train_for_compare, validation_data = (x_val_scaled, y_val), batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "    threshold = 0.5\n",
    "    y_val_pred = (model.predict(x_val_scaled) >= threshold).astype(int)\n",
    "    return accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "run_study(create_lstm_study_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "Best trial:\n",
      "Accuracy: 0.5374149659863946\n",
      "Best hyperparameters:\n",
      "units: 21\n",
      "optimizer: Adam\n",
      "batch_size: 15\n",
      "epochs: 4\n",
      "lr: 0.018368809250582617\n"
     ]
    }
   ],
   "source": [
    "def create_lstm_gru(units):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(LSTM(units, return_sequences=True, input_shape=(x_train_lstm.shape[1], 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(GRU(units))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=units // 2))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    return model\n",
    "\n",
    "def create_lstm_gru_study(trial: Trial):\n",
    "    units = trial.suggest_int(\"units\", low=10, high = 50)\n",
    "    model = create_lstm_2(units)\n",
    "    optimizer = trial.suggest_categorical('optimizer', \n",
    "                                         [\"Adam\", \"SGD\", \"RMSprop\", \"Adagrad\"])\n",
    "    batch_size = trial.suggest_int('batch_size', low=1, high = 15)\n",
    "    epochs = trial.suggest_int('epochs', low=1, high=5)\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
    "    model.compile(optimizer=getattr(tf.keras.optimizers, optimizer)(learning_rate=lr), loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "    model.fit(x_train_lstm, Y_train_for_compare, validation_data = (x_val_scaled, y_val), batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "    threshold = 0.5\n",
    "    y_val_pred = (model.predict(x_val_scaled) >= threshold).astype(int)\n",
    "    return accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "run_study(create_lstm_gru_study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
